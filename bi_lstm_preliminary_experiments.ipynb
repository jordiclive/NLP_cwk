{"cells":[{"cell_type":"code","metadata":{"cell_id":"00001-7336c37f-9f14-45cc-9cf2-b672cc42de3d","deepnote_to_be_reexecuted":false,"source_hash":null,"execution_millis":148,"execution_start":1614687953809,"output_cleared":true,"deepnote_cell_type":"code"},"source":"# You will need to download any word embeddings required for your code, e.g.:\n\n!wget http://nlp.stanford.edu/data/glove.6B.zip\n!unzip glove.6B.zip\n\n# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n\n#! pip install torch","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00002-63d66686-607a-44ee-ba9d-e2885a360a29","deepnote_to_be_reexecuted":false,"source_hash":"cc03154a","execution_millis":2547,"execution_start":1614688055465,"deepnote_cell_type":"code"},"source":"# Imports\nimport regex as re\nimport matplotlib.pyplot as plt \nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom torch.utils.data import Dataset, random_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport codecs\nfrom numpy import dot\nfrom numpy.linalg import norm","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00003-acd508b0-4d4e-4e65-8bbe-a8f16903704b","deepnote_to_be_reexecuted":false,"source_hash":"3e2c4eff","execution_millis":11,"execution_start":1614688061682,"deepnote_cell_type":"code"},"source":"# Setting random seed and device\nSEED = 1\n\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")","execution_count":2,"outputs":[{"name":"stderr","text":"/shared-libs/python3.7/py/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n  return torch._C._cuda_getDeviceCount() > 0\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00004-5ba458c7-b322-448b-81f4-cd8c07b7328a","deepnote_to_be_reexecuted":false,"source_hash":"3c829f6c","execution_millis":34,"execution_start":1614688064379,"deepnote_cell_type":"code"},"source":"# Load data\ntrain_df = pd.read_csv('/work/NLP_cwk/data/task-1/train.csv')\ntest_df = pd.read_csv('/work/NLP_cwk/data/task-1/dev.csv')","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00005-c2469f62-6ad1-4768-85ac-ce443530d60f","deepnote_to_be_reexecuted":false,"source_hash":"13bc4ea4","execution_millis":0,"execution_start":1614689749826,"deepnote_cell_type":"code"},"source":"# Number of epochs\nepochs = 5\n\n# Proportion of training data for train compared to dev\ntrain_proportion = 0.8","execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00006-f7aa3118-d72d-4e72-96ea-de8472b00121","deepnote_to_be_reexecuted":false,"source_hash":"53b8c481","execution_millis":1,"execution_start":1614688070680,"deepnote_cell_type":"code"},"source":"# We define our training loop\ndef train(train_iter, dev_iter, model, number_epoch):\n    \"\"\"\n    Training loop for the model, which calls on eval to evaluate after each epoch\n    \"\"\"\n    train_RMSEs = []\n    val_RMSEs = []\n\n    print(\"Training model.\")\n\n    for epoch in range(1, number_epoch+1):\n\n        model.train()\n        epoch_loss = 0\n        epoch_sse = 0\n        no_observations = 0  # Observations used for training so far\n\n        for batch in train_iter:\n\n            feature, original_mask, edit_mask, target = batch\n\n            feature, original_mask, edit_mask, target = feature.to(device), original_mask.to(device), edit_mask.to(device), target.to(device)\n\n            # for RNN:\n            model.batch_size = target.shape[0]\n            no_observations = no_observations + target.shape[0]\n            model.hidden = model.init_hidden()\n\n            predictions = model(feature, original_mask, edit_mask).squeeze(1)\n\n            optimizer.zero_grad()\n\n            loss = loss_fn(predictions, target)\n\n            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()*target.shape[0]\n            epoch_sse += sse\n\n        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n\n        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n\n        train_RMSEs.append(epoch_mse**0.5)\n        val_RMSEs.append(valid_mse**0.5)\n\n        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n\n    return train_RMSEs, val_RMSEs","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00007-946b74bd-d70b-48aa-b015-1c2575f2ed0d","deepnote_to_be_reexecuted":false,"source_hash":"d5622ea5","execution_millis":0,"execution_start":1614688074524,"deepnote_cell_type":"code"},"source":"# We evaluate performance on our dev set\ndef eval(data_iter, model):\n    \"\"\"\n    Evaluating model performance on the dev set\n    \"\"\"\n    model.eval()\n    epoch_loss = 0\n    epoch_sse = 0\n    pred_all = []\n    trg_all = []\n    no_observations = 0\n\n    with torch.no_grad():\n        for batch in data_iter:\n            feature, original_mask, edit_mask, target = batch\n\n            feature, original_mask, edit_mask, target = feature.to(device), original_mask.to(device), edit_mask.to(device), target.to(device)\n\n            # for RNN:\n            model.batch_size = target.shape[0]\n            no_observations = no_observations + target.shape[0]\n            model.hidden = model.init_hidden()\n\n            predictions = model(feature, original_mask, edit_mask).squeeze(1)\n            loss = loss_fn(predictions, target)\n\n            # We get the mse\n            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n            sse, __ = model_performance(pred, trg)\n\n            epoch_loss += loss.item()*target.shape[0]\n            epoch_sse += sse\n            pred_all.extend(pred)\n            trg_all.extend(trg)\n\n    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00008-2749102f-a2b9-4662-8a76-9a9d2b92df8a","deepnote_to_be_reexecuted":false,"source_hash":"a4a2a417","execution_millis":5,"execution_start":1614688077539,"deepnote_cell_type":"code"},"source":"# How we print the model performance\ndef model_performance(output, target, print_output=False):\n    \"\"\"\n    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n    \"\"\"\n\n    sq_error = (output - target)**2\n\n    sse = np.sum(sq_error)\n    mse = np.mean(sq_error)\n    rmse = np.sqrt(mse)\n\n    if print_output:\n        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n\n    return sse, mse","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00009-a196c167-2881-49b7-9fe2-1174a0ff12ae","deepnote_to_be_reexecuted":false,"source_hash":"336f804b","execution_millis":0,"execution_start":1614688081036,"deepnote_cell_type":"code"},"source":"def create_vocab(original_data, edit_words):\n    \"\"\"\n    Creating a corpus of all the tokens used\n    \"\"\"\n    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n    original_words = []\n    for i in range(len(original_data)):\n        sentence = original_data[i]\n        edit_word = edit_words[i]\n\n        old_words = re.findall(\"<(.*)/>\", sentence)[0].split(' ')\n\n        tokenized_sentence = []\n        for token in re.split(' |<|/>',sentence): # simplest split is\n            tokenized_sentence.append(token.lower())\n            if(old_words[-1] == token):\n                tokenized_sentence.append(edit_word.lower())\n\n        tokenized_corpus.append(tokenized_sentence)\n        original_words.append(old_words)\n\n\n    # Create single list of all vocabulary\n    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n\n    for sentence in tokenized_corpus:\n\n        for token in sentence:\n\n            if token not in vocabulary:\n\n                if True:\n                    vocabulary.append(token)\n\n    return vocabulary, tokenized_corpus, original_words","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00010-0772e863-656e-4391-8423-90aa24fbc2ff","deepnote_to_be_reexecuted":false,"source_hash":"86e4f55c","execution_millis":1,"execution_start":1614688083726,"deepnote_cell_type":"code"},"source":"def collate_fn_padd(batch):\n    '''\n    We add padding to our minibatches and create tensors for our model\n    '''\n\n    batch_original_mask = [o_m for f, o_m, e_m, l in batch]\n    batch_edit_mask = [e_m for f, o_m, e_m, l in batch]\n    batch_labels = [l for f, o_m, e_m, l in batch]\n    batch_features = [f for f, o_m, e_m, l in batch]\n\n    batch_features_len = [len(f) for f, o_m, e_m, l in batch]\n\n    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n    original_mask_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n    edit_mask_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n\n    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n\n    for idx, (mask, seqlen) in enumerate(zip(batch_original_mask, batch_features_len)):\n        original_mask_tensor[idx, :seqlen] = torch.LongTensor(mask)\n\n    for idx, (mask, seqlen) in enumerate(zip(batch_edit_mask, batch_features_len)):\n        edit_mask_tensor[idx, :seqlen] = torch.LongTensor(mask)\n\n    batch_labels = torch.FloatTensor(batch_labels)\n\n    return seq_tensor, original_mask_tensor, edit_mask_tensor, batch_labels\n\nclass Task1Dataset(Dataset):\n\n    def __init__(self, train_data, original_indices, edit_indices, labels):\n        self.x_train = train_data\n        self.y_train = labels\n        self.original_indices = original_indices\n        self.edit_indices = edit_indices\n\n    def __len__(self):\n        return len(self.y_train)\n\n    def __getitem__(self, item):\n        original_mask = torch.zeros(len(self.x_train[item])).long()\n        original_mask[self.original_indices[item]] = 1\n\n        edit_mask = torch.zeros(len(self.x_train[item])).long()\n        edit_mask[self.edit_indices[item]] = 1\n\n        return self.x_train[item], original_mask, edit_mask, self.y_train[item]","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00011-f9988d77-204d-4b7c-8b8d-d5fe6c0724ae","deepnote_to_be_reexecuted":false,"source_hash":"eb6a6b12","execution_millis":1,"execution_start":1614688937222,"deepnote_cell_type":"code"},"source":"class BiLSTM(nn.Module):\n\n    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device, experiment_type):\n        super(BiLSTM, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.embedding_dim = embedding_dim\n        self.device = device\n        self.batch_size = batch_size\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.experiment_type = experiment_type\n\n        # The LSTM takes word embeddings as inputs, and outputs hidden states\n        # with dimensionality hidden_dim.\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, dropout = 0.5)\n\n        # The linear layer that maps from hidden state space to tag space\n        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n        self.hidden = self.init_hidden()\n\n        #Dissimilarity score to funninness\n        self.dissim2label = nn.Linear(1,1)\n\n    def init_hidden(self):\n        # Before we've done anything, we dont have any hidden state.\n        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n\n    def forward(self, sentence, original_mask, edit_mask):\n        embedded = self.embedding(sentence)\n        embedded = embedded.permute(1, 0, 2)\n\n        lstm_out, self.hidden = self.lstm(\n            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n\n        original_mask = original_mask.transpose(0,1).unsqueeze(-1)\n        edit_mask = edit_mask.transpose(0,1).unsqueeze(-1)\n\n        original_lstm_out = lstm_out*original_mask\n        edit_lstm_out = lstm_out*edit_mask\n\n        original_lstm_out = original_lstm_out.sum(0)\n        edit_lstm_out = edit_lstm_out.sum(0)\n\n        original_lstm_out = original_lstm_out.div(original_mask.sum(0))\n        edit_lstm_out = edit_lstm_out.div(edit_mask.sum(0))\n\n        if  self.experiment_type == 'insert_after':\n            out = self.hidden2label(lstm_out[-1])\n\n        if self.experiment_type == 'original_representation':\n            out = self.hidden2label(original_lstm_out)\n\n        elif self.experiment_type == 'cosine_distance':\n            cos_dissim = 1 - torch.sum(original_lstm_out* edit_lstm_out, dim = 1)/(torch.norm(original_lstm_out, dim =1 )*torch.norm(edit_lstm_out, dim =1))\n            cos_dissim = cos_dissim.unsqueeze(-1)\n            out = self.dissim2label(cos_dissim)\n\n        elif self.experiment_type == 'simple_difference':\n            out = original_lstm_out - edit_lstm_out\n            out = self.hidden2label(out)\n            \n        return out","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"cell_id":"00012-0cc54716-2382-496a-9e30-826db03616f7","deepnote_to_be_reexecuted":false,"source_hash":"bc9b03cb","execution_millis":12483,"execution_start":1614688941478,"deepnote_cell_type":"code"},"source":"## Approach 1 code, using functions defined above:\n\n# We set our training data and test data\ntrain_original_data = train_df['original']\ntrain_edit_words = train_df['edit']\ntest_original_data = test_df['original']\ntest_edit_words = test_df['edit']\n\n# Creating word vectors\ntraining_vocab, training_tokenized_corpus, training_original_words = create_vocab(train_original_data, train_edit_words)\ntest_vocab, test_tokenized_corpus, test_original_words = create_vocab(test_original_data, test_edit_words)\n\n# Creating joint vocab from test and train:\njoint_vocab, joint_tokenized_corpus, joint_original_words = create_vocab(\n  pd.concat([train_original_data, test_original_data], ignore_index= True), \n  pd.concat([train_edit_words, test_edit_words], ignore_index= True))\nprint(\"Vocab created.\")","execution_count":11,"outputs":[{"name":"stdout","text":"Vocab created.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00013-602d4069-b011-4207-87c5-3c568abf90c2","deepnote_to_be_reexecuted":false,"source_hash":"2021b7c0","execution_millis":118695,"execution_start":1614688977354,"deepnote_cell_type":"code"},"source":"# We create representations for our tokens\nwvecs = [] # word vectors\nword2idx = [] # word2index\nidx2word = []\n\n# This is a large file, it will take a while to load in the memory!\nwith codecs.open('glove.6B.100d.txt', 'r','utf-8') as f:\n  index = 1\n  for line in f.readlines():\n    # Ignore the first line - first line typically contains vocab, dimensionality\n    if len(line.strip().split()) > 3:\n      word = line.strip().split()[0]\n      if word in joint_vocab:\n          (word, vec) = (word,\n                     list(map(float,line.strip().split()[1:])))\n          wvecs.append(vec)\n          word2idx.append((word, index))\n          idx2word.append((index, word))\n          index += 1\n\nword2idx.append(('<pad>', 0))\nidx2word.append((0, '<pad>'))\nwvecs = np.insert(wvecs, 0, 0., axis=0)\nwvecs = np.array(wvecs)\nword2idx = dict(word2idx)\nidx2word = dict(idx2word)\n\nvectorized_seqs = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in training_tokenized_corpus]\n\n# To avoid any sentences being empty (if no words match to our word embeddings)\nvectorized_seqs = [x if len(x) > 0 else [0] for x in vectorized_seqs]\n","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00014-1897f4f7-c8d7-4d05-8528-e720b5d7556c","deepnote_to_be_reexecuted":false,"source_hash":"8e1fec05","execution_millis":62,"execution_start":1614689112774,"deepnote_cell_type":"code"},"source":"#Find the position of the original words in the new vectorized sequence\ncorpus_original_indices = []\ncorpus_edit_indices = []\nfor i in range(len(vectorized_seqs)):\n    sentence_original_indices = []\n    sentence_edit_indices = []\n    seq = [idx2word[index] for index in vectorized_seqs[i]]\n    for word in training_original_words[i]:\n        if(word.lower() in seq):\n            sentence_original_indices.append(seq.index(word.lower()))\n    if(train_edit_words[i].lower() in seq):\n        sentence_edit_indices.append(seq.index(train_edit_words[i].lower()))\n    if not sentence_original_indices:\n        sentence_original_indices.append(-1)\n    if not sentence_edit_indices:\n        sentence_edit_indices.append(-1)\n    corpus_original_indices.append(sentence_original_indices)\n    corpus_edit_indices.append(sentence_edit_indices)","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00014-b904d03b-fc9b-42e7-a019-8790ea6419ff","deepnote_to_be_reexecuted":false,"source_hash":"1a06daa8","execution_millis":33,"execution_start":1614689754742,"deepnote_cell_type":"code"},"source":"INPUT_DIM = len(word2idx)\nEMBEDDING_DIM = 100\nBATCH_SIZE = 32\nHIDDEN_DIM = 40\n#Replicate experiment with cosine distance(edited_repr, original_repr) passed to output\n#experiment_type = 'cosine_distance'\n#Replicate experiment with last hidden state passed to output\n#experiment_type = 'insert_after'\n#Replicate experiment original_repr passed to output\n#experiment_type = 'original_representation'\n#Replicate experiment with difference(edited_repr, original_repr) passed to output\nexperiment_type = 'simple_difference'\n#Specify following variable False to replicate experiments with embedding finetuned\nfreeze_embeddings = True\n\n\nmodel = BiLSTM(EMBEDDING_DIM, HIDDEN_DIM, INPUT_DIM, BATCH_SIZE, device, experiment_type)\nprint(\"Model initialised.\")\n\nmodel.to(device)\n# We provide the model with our embeddings\nmodel.embedding.weight.data.copy_(torch.from_numpy(wvecs))\nif(freeze_embeddings):\n    model.embedding.weight.requires_grad = False\n\nfeature = vectorized_seqs\n\n# 'feature' is a list of lists, each containing embedding IDs for word tokens\ntrain_and_dev = Task1Dataset(feature, corpus_original_indices, corpus_edit_indices, train_df['meanGrade'])\n\ntrain_examples = round(len(train_and_dev)*train_proportion)\ndev_examples = len(train_and_dev) - train_examples\n\ntrain_dataset, dev_dataset = random_split(train_and_dev,\n                                           (train_examples,\n                                            dev_examples))\n\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\ndev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n\nprint(\"Dataloaders created.\")","execution_count":25,"outputs":[{"name":"stdout","text":"Model initialised.\nDataloaders created.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00013-44ffeabe-e547-4260-a953-adc5ce743313","deepnote_to_be_reexecuted":false,"source_hash":"895b74b1","execution_millis":42392,"execution_start":1614689756676,"deepnote_cell_type":"code"},"source":"loss_fn = nn.MSELoss()\nloss_fn = loss_fn.to(device)\n\noptimizer = torch.optim.Adam(model.parameters())\n\ntrain_RMSEs, val_RMSEs = train(train_loader, dev_loader, model, epochs)","execution_count":26,"outputs":[{"name":"stdout","text":"Training model.\n| Epoch: 01 | Train Loss: 0.46 | Train MSE: 0.46 | Train RMSE: 0.68 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n| Epoch: 02 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n| Epoch: 03 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |         Val. Loss: 0.32 | Val. MSE: 0.32 |  Val. RMSE: 0.57 |\n| Epoch: 04 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.32 | Val. MSE: 0.32 |  Val. RMSE: 0.57 |\n| Epoch: 05 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=cd0ae3bf-8b9c-46ca-9eb4-5ef4b3522174' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"deepnote_notebook_id":"29d3f26a-7635-4b96-8c87-dcbf9ba8d600","deepnote":{},"deepnote_execution_queue":[]}}